Many Microbe Microarrays Database (M3D) Data Preparation
=======================================================

```{r knitr_settings, include=FALSE}
library(knitr)
opts_knit$set(progress=TRUE, verbose=TRUE)
opts_chunk$set(fig.width=1080/96,
               fig.height=1080/96,
               dpi=96)
```

```{r run_date, results='asis', echo=FALSE}
email = "<a href='mailto:khughitt@umd.edu'>Keith Hughitt</a>"
last_update = format(Sys.time(), "(<time>%Y-%m-%d</time>)")
cat(paste(email, last_update))

# Clean up any existing variables
rm(list=ls())
```

[view source](README.rmd)

Overview
========

Below we will load in some E. coli transcriptome data from the [Many Microbe
Microarrays Database (M<sup>3D</sup>)](http://www.m3d.mssm.edu), and explore
some basic properties of the data.

Hopefully, the code below will provide a good starting point for future R-based
network analyses of the data.

The data included in this repo and used below comes M<sup>3D</sup> build 6,
accessed on July 16, 2014. Currently, the gene only normalized version of the
**E. coli** microarray data is used. In the future it may be worth analyzing
the raw data and including probes for intergenic regions.

Methods
=======

Load libraries
-------------

```{r load_libraries}
library(cbcbSEQ)
library(reshape2)
library(RColorBrewer)
library(dplyr)
library(gplots)
library(ggplot2)
library(limma)
```

Load data
---------

### Load feature data

To begin, let's load in some of the metadata which describes the sources and
experimental conditions included in the microarray datasets.

```{r load_feature_data}
# load feature data
features_long = tbl_df(read.delim('input/E_coli_v4_Build_6.experiment_feature_descriptions'))
features_long = features_long %>% select(experiment_name, feature_name, value)

# remove any NA features (found one in above dataset)
features_long = features_long %>% filter(!is.na(feature_name))

# list of features included in datasets
unique(features_long$feature_name)

# flatten feature data
feature_data = tbl_df(dcast(features_long, experiment_name ~ feature_name,
                            value.var="value"))
dim(feature_data)

# not all of the features are guaranteed to be covered for a given sample. This
# means that there will be a number of NAs in the data:
feature_data[1:5,1:5]

# which features which have values set for every sample?
features = colnames(feature_data)
features[complete.cases(t(feature_data))]

# distribution of strains
head(sort(table(feature_data$strain), decreasing=TRUE), 10)
```

This gives us a pretty good place to start. let's build a simplified design
matrix including sample id, experiment (~batch), and XXXX feature.

#### Limit to K12 MG1655 strain

For simplicity, let's focus for now on one strain:

- [E. coli K12 MG1655](http://www.genome.wisc.edu/resources/strains.htm)

This is the most widely studied strain in the dataset and includes nearly half
of all of the samples included in M<sup>3D</sup>.

```{r clean_feature_data}
feature_data = feature_data %>% filter(strain %in% c('MG1655', 'MG1655_yale'))

# remove any features for which there are no longer any relevant samples
feature_data = feature_data[,features[colSums(!is.na(feature_data)) > 0]]
features = colnames(feature_data)

# number of samples remaining
nrow(feature_data)
```

#### Explore features in dataset

Next, let's see which features are most commonly studied.

```{r feature_exploration}
# most common features
sort(colSums(!is.na(feature_data)), decreasing=TRUE)

# temperature
table(as.numeric(feature_data$culture_temperature))

# time
# we would need to normalize the units before making any comparisons here
table(feature_data$time_point)

# cell density
table(feature_data$cell_density)

# growth phase
table(feature_data$growth_phase)
```

Growth phase exploration
------------------------

Let's start by looking at growth phase since there is a large number of samples
with known growth phase information and the number of samples in each phase is
decent.

```{r select_growth_phase_data, results='asis'}
# discard samples with no growth phase information
feature_data = feature_data[!is.na(feature_data$growth_phase),]

# drop other unrelated features (for now...)
feature_data = feature_data %>% select(experiment_name, experimenter,
                                       growth_phase, strain)
rownames(feature_data) = 1:nrow(feature_data)
```

#### Sample design

```{r sample_summary, results='asis'}
kable(feature_data)

# load experiment data (includes experiment/replicate mapping)
experiment_data = tbl_df(read.delim('input/E_coli_v4_Build_6.experiment_descriptions'))
dim(experiment_data)

# drop chips that are not related to our design
experiment_data = experiment_data %>% filter(experiment_name %in%
                                             feature_data$experiment_name)
dim(experiment_data)

# design
design = data.frame(
    condition=feature_data$growth_phase[match(experiment_data$experiment_name,
                                              feature_data$experiment_name)],
    batch=experiment_data$experiment_name
)
```

That should be good for now. Now let's move onto the actual expression data.

### Load expression data

```{r load_expression_data}
# expression data
raw_data = tbl_df(read.delim('input/E_coli_v4_Build_6_chips907probes4297.tab.gz',
                             row.names=1))
dim(raw_data)

raw_data = raw_data[,colnames(raw_data) %in% experiment_data$chip_name]
dim(raw_data)
```

### Helper functions

Before continuing, let's first load a few helper functions that will be useful
in the downstream analysis...

```{r helper_functions}
#
# Choose colors to use when plotting sample condition and batch
#
sample_plot_colors = function (condition, batch) {
    # Convert to factor if not already and remove any unused levels
    condition = factor(condition)
    batch = factor(batch)

    # Batch colors
    if (nlevels(batch) > 1) {
        if (nlevels(batch) <= 12) {
            rc=brewer.pal(12, "Set3")[as.integer(batch)]
        } else {
            rc=rainbow(nlevels(batch))[as.integer(batch)]
        }
    } else {
        rc = rep("green", length(batch))
    }

    # Condition colors
    if (nlevels(condition) > 1) {
        if (nlevels(condition) <= 9) {
            cc=brewer.pal(9,"Set1")[as.integer(condition)]
        } else {
            cc=tail(rainbow(nlevels(condition) +
                            nlevels(batch)),
                    nlevels(condition))[as.integer(condition)]
        }
    } else {
        cc =  rep("red",length(condition))
    }

    return(list("batch"=rc, "condition"=cc))
}

#
# Plot sample heatmap
#
plot_sample_heatmap = function (counts, condition, batch,
                                metric='dist', col='heat.colors') {
    # Compute euclidean distance or pearson correlation between samples
    if (metric == 'dist') {
        dists = dist(t(counts))
        mat = as.matrix( dists )
    } else if (metric == 'pearson') {
        mat = cor(counts)
    }

    # Select plot colors
    plot_colors = sample_plot_colors(condition, batch)

    # Heatmap plot
    hv = heatmap.2(mat, margin=c(6, 6), trace="none", key=FALSE, col=col,
                   RowSideColors=plot_colors$batch,
                   ColSideColors=plot_colors$condition)
    legend(x="topleft", legend=unique(condition),
           col=unique(plot_colors$condition), pch=15)
    #legend(x="topright", legend=unique(batch),
    #       col=unique(plot_colors$batch), pch=15)
}

#
# Plot sample PCA components
#
plot_sample_pca = function(counts, condition, batch, main="", axis1=1, axis2=2,
                           include_table=TRUE) {
    # PCA
    pca = makeSVD(counts)
    pcVar = round((pca$d^2) / sum(pca$d^2) * 100, 2)

    # X and Y axis labels
    xl = sprintf("PC%d: %.2f%% variance", axis1, pcVar[axis1])
    yl = sprintf("PC%d: %.2f%% variance", axis2, pcVar[axis2])

    # Create combined data frame
    pcaData = data.frame(SampleID=colnames(counts),
                         PC1=pca$v[,axis1], PC2=pca$v[,axis2],
                         Condition=condition, Batch=batch)

    # Plot specified principle components
    plt = ggplot(pcaData, aes(PC1, PC2, color=Condition, shape=Batch)) +
        geom_point(stat="identity",size=5) +
        #geom_text(aes(label=SampleID), angle=45, size=4,vjust=2) +
        xlab(xl) + ylab(yl) +
        ggtitle(sprintf("%s (PC%d vs. PC%d)", main, axis1, axis2)) +
        theme(axis.ticks=element_blank(), axis.text.x=element_text(angle=-90))
    print(plt)

    # Compute variance of each PC and how they correlate with batch and
    # condition
    if (nlevels(batch) > 1) {
        pcs = pcRes(pca$v, pca$d, condition, batch)
    } else {
        pcs = pcRes(pca$v, pca$d, condition)
    }
    rownames(pcs) = paste0("PC", rownames(pcs))

    kable(head(pcs, 30))
}
```

### Samples

```{r sample_relationships, results='asis'}
plot_sample_pca(raw_data,
                condition=design$condition,
                batch=design$batch)

plot_sample_heatmap(raw_data, design$condition, design$batch)
```

### Removing batch from the data

```{r batch_residuals, results='asis'}
batch = design$batch

model_batch = model.matrix(~batch)
#voom_batch  = voom(normed_counts, model_batch)
#fit_batch = lmFit(voom_batch)

# Get the residuals (everything but batch effect)
#batch_residuals = residuals(fit_batch, voom_batch)

#plot_sample_pca(batch_residuals[,include], design_final, "Batch included in linear model")

#plot_sample_heatmap(batch_residuals[,include], design_final)
```

Discussion
==========

Questions
---------

1. Dealing with batch
    - In the context of a combined dataset such as this, does the use of
      `experiment_name` as batch make the most sense?
    - Are there other better ways to divide up the dataset or to choose
      experiments to exclude? (e.g. remove all perturbations)
    - Would it be possible to include more than one non-biological variable in
      the model, e.g. `experimenter_name`?
2. Exploratory data analysis
    - Any other methods for exploring the initial dataset that would be worth
      trying out?
         - biplots, biological effect residuals, etc.
3. Higher-dimension dataset
    - In the above analysis, I started by removing all of the features, save for
      one batch and one biological variable of interest. Are there other ways to
      make use of the dataset as-is, or at least, with more of the features
      included?
4. Network analysis
    - Would this dataset be appropriate to use for constructing a co-expression
      or gene-regulatory network? What other information might we need?
    - If so, what part(s) of the data should be used? and what should be
      excluded?

Where to next?
--------------

Some things that might be worth pursuing from here:

- Pull in some additional annotation data:
    - [BSgenome.Ecoli.NCBI.20080805](http://www.bioconductor.org/packages/2.13/data/annotation/html/BSgenome.Ecoli.NCBI.20080805.html), or,
    - [org.EcK12.eg.db](http://www.bioconductor.org/packages/2.13/data/annotation/html/org.EcK12.eg.db.html)
- Start with raw data and clean/normalize ourselves.
- Make use of one of the larger M<sup>3D</sup> datasets, such as the one which
  includes intergenic regions.
- Investigate other sources of information and data:
    - [Reactome](http://www.reactome.org/)
    - [EcoCyc](http://ecocyc.org/)
- Read/discuss a paper where a E. coli network is constructed and validated
  using some of these resources.
- Start trying out some of the methods we come across on our cleaned up
  dataset.
- **Come up with a researh question...**

System Information
------------------

```{r sysinfo}
sessionInfo()
date()
```

References
----------

```{r refs, include=FALSE}
library(knitcitations)
cleanbib()
citep('10.1093/nar/gkm815')
```

```{r refs_output, echo=FALSE, results='asis'}
bibliography('html')
```
